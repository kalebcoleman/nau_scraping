---
title: "NAU AI & Ethics Course Analysis"
author: "Kaleb Coleman"
date: "`r Sys.Date()`"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
data_dir <- "outputs"
```

# Data Collection

I scraped course data from the NAU catalog using `scrape.py`, which iterates across
course prefixes and terms, then writes results to `outputs/nau_courses.csv`. all empty prefixes were logged to `outputs/nau_empty_prefixes.csv`.

I appended three missing prefixes that were not listed in the PDF: `MRE`, `BAN`, and `STAT`. This added additional courses to the dataset and updated the AI candidate list.

```{r load-data}
courses <- read.csv(file.path(data_dir, "nau_courses.csv"))
summary_metrics <- read.csv(file.path(data_dir, "nau_summary.csv"))
prefix_totals <- read.csv(file.path(data_dir, "nau_prefix_totals.csv"))
empty_prefixes_path <- file.path(data_dir, "nau_empty_prefixes.csv")
empty_prefixes <- read.csv(empty_prefixes_path, stringsAsFactors = FALSE)
if (!all(c("term", "term_code", "prefix", "error") %in% colnames(empty_prefixes))) {
  empty_prefixes <- read.csv(empty_prefixes_path, header = FALSE, stringsAsFactors = FALSE)
  colnames(empty_prefixes) <- c("term", "term_code", "prefix", "error")
}
courses_unique <- unique(courses[, c("prefix", "number", "title")])
flags_full <- read.csv(file.path(data_dir, "nau_courses_with_flag.csv"))
flags_unique <- read.csv(file.path(data_dir, "nau_unique_courses_with_flag.csv"))
```

Total unique courses (by prefix + number):

```{r total-unique}
knitr::kable(summary_metrics, row.names = FALSE)
```

Sample of raw course rows (first 5):

```{r sample-raw}
knitr::kable(head(courses[, c("prefix", "number", "title")], 5), row.names = FALSE)
```

Missing prefixes:

```{r missing-prefixes}
missing_prefixes <- sort(unique(empty_prefixes$prefix[empty_prefixes$error == "empty"]))
knitr::kable(data.frame(prefix = missing_prefixes), row.names = FALSE)
```

# Initial AI Analysis (High-Confidence Core)

I ran a **narrow, high-precision** AI search using `ai_analysis.py`. This produces
the core AI list (`nau_courses_ai_subset.csv`) and a full dataset with AI + ethics
flags (`nau_courses_with_flag.csv`). The core list is treated as a benchmark for
high-confidence AI-related courses.

```{r core-ai}
ai_core <- read.csv(file.path(data_dir, "nau_courses_ai_subset.csv"))
knitr::kable(ai_core[, c("prefix", "number", "title")], row.names = FALSE)
```

Total AI related courses: `r nrow(ai_core)`

# Expanded AI Analysis (Recall-First)

To avoid missing relevant courses, I ran a broader search with `ai_analysis_broad.py`.
This produces:

```{r ai-expanded, include=FALSE}
ai_candidates <- read.csv(file.path(data_dir, "nau_courses_ai_candidates.csv"))
knitr::kable(
  data.frame(metric = "Broad AI candidates", value = nrow(ai_candidates)),
  row.names = FALSE
)
```
- `nau_courses_ai_candidates.csv`
- Total AI candidates `r nrow(ai_candidates)`

I manually reviewed the broad candidate list and found a mix of true AI‑adjacent
material and false positives. Some matches came from non‑AI contexts (for example,
courses about teaching/learning that triggered on “learning” or “intelligent”), while
others surfaced useful applied topics. The full scope is documented in the separate
appendix PDF (`ai_candidates_report.pdf`), generated from `ai_candidates_report.Rmd`.
That appendix includes the core AI list, the AI‑adjacent highlights, and the remaining
non‑core candidates, so the entire candidate set is available for review.

\newpage

## AI-Adjacent Highlights

I also highlight a few **AI‑adjacent** courses that use related methods (e.g., robotics
or image processing) even if they are not explicitly labeled as AI in the catalog.

```{r ai-adjacent}
adjacent_keys <- data.frame(
  prefix = c("ART", "EE", "BAN", "EE", "MRE"),
  number = c("376", "442", "440", "526", "471"),
  stringsAsFactors = FALSE
)
adjacent <- merge(adjacent_keys, courses_unique, by = c("prefix", "number"), all.x = TRUE)
knitr::kable(adjacent[, c("prefix", "number", "title")], row.names = FALSE)
```

# Ethics Analysis

Ethics courses were identified with `ethics_analysis.py`, using a conservative rule
set to avoid casual mentions of ethics in unrelated contexts.

```{r ethics}
ethics <- read.csv(file.path(data_dir, "nau_courses_ethics_subset.csv"))

# Show a sample to keep the report concise.
knitr::kable(head(ethics[, c("prefix", "number", "title")], 5), row.names = FALSE)
```

Total ethics courses: `r nrow(ethics)`

# Keyword Strategy (AI + Ethics)

I used a keyword‑driven approach because the catalog provides only titles and short
descriptions. For **AI**, I prioritized explicit phrases that reliably indicate AI
instruction (for example, “artificial intelligence,” “machine learning,” “deep learning,”
“computer vision,” “NLP,” “LLM/GPT”). This makes the core list high‑confidence. I also
used a fuzzy matcher to catch small variations or typos in those same phrases.

For **ethics**, I used direct ethics terms (for example, “ethics,” “bioethics,”
“professional ethics,” “ethical decision‑making”) across both titles and descriptions.

This strategy works well because:

- It **minimizes false positives** in the core AI list by requiring explicit AI language.
- It **captures real course intent** as written in the catalog (the best available data source).
- It remains **auditable and explainable**: every flagged course can be traced back to
  a specific keyword match, which makes manual review straightforward.

# AI + Ethics Overlap

Courses flagged as **both** AI-related and ethics-related:

```{r ai-ethics-overlap}
ai_flag <- tolower(as.character(flags_unique$is_ai_related)) %in% c("true", "1", "t", "yes")
ethics_flag <- tolower(as.character(flags_unique$is_ethics_related)) %in% c("true", "1", "t", "yes")
ai_ethics <- flags_unique[ai_flag & ethics_flag, c("prefix", "number", "title")]
rownames(ai_ethics) <- NULL
knitr::kable(ai_ethics, row.names = FALSE)
```

\newpage

# Conclusion

This analysis identifies a robust catalog of `r summary_metrics$value[summary_metrics$metric == "total_unique_courses"]`
unique courses at NAU, but only `r nrow(ethics)` are ethics‑focused and only
`r nrow(ai_core)` are high‑confidence AI courses. Relative to the full catalog, both
ethics and AI coverage appear limited. The overlap between these two areas is minimal:
only one course (PRM 165) is flagged as both AI‑related and ethics‑related. This points
to a curricular gap in **AI‑specific ethics** coverage.

AI also appears outside traditional tech departments. PRM 165 (Parks & Recreation
Management) directly addresses AI’s impact on leisure, and the PSY 305 / PSY 305H
courses explicitly connect AI to psychology research and careers. These are important
signals that AI concepts are reaching applied and social‑science contexts, but the
overall count remains small.

The “Special Topics” numbers (for example, `499`, `599`, `699`) are a black box for this
type of scrape. The catalog often lists only a generic placeholder, so rotating AI‑related
topics are invisible in the data. A future audit would need **manual syllabus review**
or **interviews with department chairs** to uncover AI or AI‑ethics content taught under
these headers.

**Strategic recommendations based on the data:**

- **Curriculum development:** The broad candidate list ( `r nrow(ai_candidates)` courses )
  shows AI‑adjacent content emerging across departments. NAU could integrate explicit
  AI‑ethics modules into technical tracks (CS, INF, EE) to close the ethics gap.
- **Ethics specificity:** Ethics is present across the catalog, but AI‑specific ethics is
  rare. Treating AI‑ethics as a distinct category (not just “ethics”) would help track
  growth in this area.
- **Data maintenance:** The prefix list is based on `data/Course-Numbering-and-Prefixes.pdf`.
  If NAU adds or removes prefixes and the PDF is out of date, those changes will not
  appear in the scrape. A periodic prefix refresh should be part of future updates.
  The “missing prefixes” table should be interpreted cautiously: it only reflects
  prefixes that returned zero results during the scrape, and it will not surface
  prefixes that exist but were omitted from the PDF source (for example, BAN, MRE, STAT).

GitHub: [github.com/kalebcoleman/nau-course-scraping](https://github.com/kalebcoleman/nau-course-scraping)
